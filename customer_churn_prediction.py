# -*- coding: utf-8 -*-
"""customer churn prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WlOvSmomaVx1nrhuV3vG6ipdJVDTUhh1
"""

import pandas as pd
import numpy as np

df=pd.read_csv("https://github.com/YBIFoundation/Dataset/raw/main/TelecomCustomerChurn.csv")

df.head()

df.isnull().sum()

df.info()

df.describe()

df.isna().sum()

df.isna().sum()*100/len(df)

for col in df.columns:
  print(col)
  print(df[col].unique())
  print("")

df['DeviceProtection'].value_counts()

df['PaperlessBilling'].value_counts()

"""#MERGE THE SAME FEATURE"""

df['OnlineSecurity'].value_counts()

"""Visulizing the data"""

import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
import matplotlib .pyplot as plt
from sklearn .model_selection import GridSearchCV

import warnings
warnings.filterwarnings("ignore")

#plt.figure(figsize=(20,160))
#plt.subplot(4,3,3)
#sns.boxplot(x='Churn',y='MonthlyCharges',data=df)
#plt.subplot(4,3,2)
#sns.boxplot(x='Churn',y='TotalCharges',data=df)
#plt.subplot(4,3,2)
#sns.boxplot(x='Churn',y='Contract',data=df)
#plt.subplot(4,3,2)
#sns.boxplot(x='Churn',y='PaymentMethod',data=df)
#plt.subplot(2,2,2)
#sns.boxplot(x='Churn',y='Tenure',data=df)
#plt.subplot(2,2,2)

#plt.show()

"""separate the categorical and numercial column"""

categorical_features=['Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport']
numerical_features=['Tenure','SeniorCitizen']

df_features=df[numerical_features + categorical_features +['Churn']  ]
df_features.head(10)

"""create Feature from the data"""

def train_test_split_and_features(df_features):
  y=df_features['Churn']
  x=df_features.drop('Churn',axis=1)
  x=pd.get_dummies(x,dtype=int)
  x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)
  print(x.head(5))
  print(x.columns)
  features=list(x.columns)
  return x_train,x_test,y_train,y_test,features

x_train,x_test,y_train,y_test,features=train_test_split_and_features(df_features)

x_train.head(10)

y_train.head(10)

# apply Random forest

def fit_and_evaluate_model(x_train,x_test,y_train,y_test,max_depth=5,min_samples_split=0.01,max_features=0.8,max_samples=0.8):
  random_forest= RandomForestClassifier(random_state=0,\
                                        max_depth=max_depth,\
                                       min_samples_split=min_samples_split,\
                                        max_features=max_features,
                                        max_samples=max_samples)
  model = random_forest.fit(x_train,y_train)
  random_forest_predict=random_forest.predict(x_test)
  random_forest_conf_matrix=confusion_matrix(y_test,random_forest_predict)
  random_forest_acc_score=accuracy_score(y_test,random_forest_predict)
  print("confusion matrix")
  print(random_forest_conf_matrix)
  print("\n")
  print("Accuracy of Random Forest:",random_forest_acc_score*100,'\n')
  print(classification_report(y_test,random_forest_predict))
  return model

model =fit_and_evaluate_model(x_train,x_test,y_train,y_test)

param_grid=[
    {'max_depth':[3,5,7,10],'min_samples_split':[0.01,0.03,0.07,0.1],
     'max_features':[0.7,0.8,0.9],
     'max_samples':[0.7,0.8,0.9,1.0]}
]

from sklearn.model_selection import GridSearchCV
model=RandomForestClassifier()
search=GridSearchCV(estimator=model,param_grid=param_grid,cv=5,verbose=5)
search.fit(x_train,y_train)

results=pd.DataFrame(search.cv_results_)
results.sort_values('mean_test_score',inplace=True,ascending=False)
results.head(10)

"""findout the best parameter"""

results_save=pd.DataFrame(search.cv_results_)
results_save.to_csv("results_save.csv",index=False)

search.best_params_

"""Evalute the model with best parameters"""

model= fit_and_evaluate_model(x_train,x_test,y_train,y_test,max_depth=10,min_samples_split=0.01,max_features=0.7,max_samples=1.0)

importances=pd.DataFrame(model.feature_importances_)
importances['features']=features
importances.columns=['importance','feature']
importances.sort_values(by='importance',ascending=True,inplace=True)

import matplotlib.pyplot as plt
plt.barh(importances.feature,importances.importance)

